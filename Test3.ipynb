{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dc14f86",
   "metadata": {},
   "source": [
    "## Mid sem presentation (Normal Approaches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f7a684",
   "metadata": {},
   "source": [
    "### Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4493a9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,roc_auc_score\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f5d93b",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6181fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cf5e6b",
   "metadata": {},
   "source": [
    "### Glimse of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e447ce34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0be4eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c600c1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Class\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5cb49a",
   "metadata": {},
   "source": [
    "### Credit card Fraud- data unbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dbbe3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhigyan/.local/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0, 0, 'Normal'), Text(1, 0, 'Fraud')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph = sns.countplot(df[\"Class\"],data=df)\n",
    "graph.set_xticklabels([\"Normal\",\"Fraud\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788fc2b9",
   "metadata": {},
   "source": [
    "### check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ddf3176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.heatmap(df.isnull(),yticklabels=False,cmap='viridis',cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f5318b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae00d3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "284802    0\n",
       "284803    0\n",
       "284804    0\n",
       "284805    0\n",
       "284806    0\n",
       "Name: Class, Length: 284807, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cccb733",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.drop([\"Class\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d374cce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V20       V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...  0.251412 -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ... -0.069083 -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...  0.524980  0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ... -0.208038 -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...  0.408542 -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53ef954",
   "metadata": {},
   "source": [
    "## splitting data in train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86815d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(df,target,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "712c96ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85443, 30)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef2d90d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199364, 30)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "459b8347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    85307\n",
       "1      136\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a612da",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e7ad8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2979fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score)}\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=42, shuffle=True) \n",
    "\n",
    "results = cross_validate(estimator=rf,\n",
    "                                          X=df,\n",
    "                                          y=target,\n",
    "                                          cv=kfold,\n",
    "                                          scoring=scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8637383e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([206.50860167, 217.03749084, 225.67588663, 231.59766674,\n",
       "        218.80506516, 222.93177891, 225.5365696 , 225.49507165,\n",
       "        224.47780919, 221.17659235]),\n",
       " 'score_time': array([0.27703834, 0.28824186, 0.28799248, 0.3579731 , 0.28504872,\n",
       "        0.36108303, 0.29108453, 0.28813171, 0.29147482, 0.2842145 ]),\n",
       " 'test_accuracy': array([0.99957867, 0.99954356, 0.99971911, 0.99943822, 0.99950844,\n",
       "        0.99947333, 0.99964889, 0.99950843, 0.99950843, 0.99968399]),\n",
       " 'test_precision': array([0.97222222, 0.97560976, 0.89473684, 0.93333333, 1.        ,\n",
       "        0.93103448, 0.975     , 0.95348837, 0.89583333, 1.        ]),\n",
       " 'test_recall': array([0.76086957, 0.76923077, 0.89473684, 0.76363636, 0.74545455,\n",
       "        0.675     , 0.8125    , 0.77358491, 0.82692308, 0.83018868]),\n",
       " 'test_f1_score': array([0.85365854, 0.86021505, 0.89473684, 0.84      , 0.85416667,\n",
       "        0.7826087 , 0.88636364, 0.85416667, 0.86      , 0.90721649])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c14679c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.785212474747307"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = np.mean(results['test_precision'])\n",
    "precision\n",
    "np.mean(results['test_recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3db6cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2eca5ace",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9996137776061234\n",
      "[[85299     8]\n",
      " [   25   111]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9999    0.9998     85307\n",
      "           1     0.9328    0.8162    0.8706       136\n",
      "\n",
      "    accuracy                         0.9996     85443\n",
      "   macro avg     0.9662    0.9080    0.9352     85443\n",
      "weighted avg     0.9996    0.9996    0.9996     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf.predict(x_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d3704d",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48b1f174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(learning_rate=0.8, n_estimators=100, random_state=42)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada = AdaBoostClassifier(n_estimators = 100, random_state = 42,algorithm='SAMME.R',\n",
    "                         learning_rate=0.8,)\n",
    "ada.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34f4bb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999403110845827\n",
      "[[85290    17]\n",
      " [   34   102]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9996    0.9998    0.9997     85307\n",
      "           1     0.8571    0.7500    0.8000       136\n",
      "\n",
      "    accuracy                         0.9994     85443\n",
      "   macro avg     0.9284    0.8749    0.8999     85443\n",
      "weighted avg     0.9994    0.9994    0.9994     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = ada.predict(x_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34458305",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f1c26df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a945dd39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9985838512224524\n",
      "[[85305     2]\n",
      " [  119    17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9986    1.0000    0.9993     85307\n",
      "           1     0.8947    0.1250    0.2194       136\n",
      "\n",
      "    accuracy                         0.9986     85443\n",
      "   macro avg     0.9467    0.5625    0.6093     85443\n",
      "weighted avg     0.9984    0.9986    0.9980     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "gb.fit(x_train,y_train)\n",
    "y_pred = gb.predict(x_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391504d0",
   "metadata": {},
   "source": [
    "## XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c849cfae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhigyan/.local/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2f984fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhigyan/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/abhigyan/.local/lib/python3.8/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:33:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.9996722961506501\n",
      "[[85301     6]\n",
      " [   22   114]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9999    0.9998     85307\n",
      "           1     0.9500    0.8382    0.8906       136\n",
      "\n",
      "    accuracy                         0.9997     85443\n",
      "   macro avg     0.9749    0.9191    0.9452     85443\n",
      "weighted avg     0.9997    0.9997    0.9997     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "xgb.fit(x_train,y_train)\n",
    "y_pred = xgb.predict(x_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c233e7",
   "metadata": {},
   "source": [
    "## Under Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a6b09983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62629f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhigyan/.local/lib/python3.8/site-packages/imblearn/utils/_validation.py:586: FutureWarning: Pass sampling_strategy=0.8 as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The samples before fit Counter({0: 199008, 1: 356})\n",
      "The samples before fit Counter({0: 445, 1: 356})\n"
     ]
    }
   ],
   "source": [
    "us = NearMiss(0.8)\n",
    "x_train_us,y_train_us = us.fit_resample(x_train,y_train)\n",
    "print(\"The samples before fit {}\".format(Counter(y_train)))\n",
    "print(\"The samples before fit {}\".format(Counter(y_train_us)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41b8b95",
   "metadata": {},
   "source": [
    "## Rf with US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5eb2747e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7099352784897534\n",
      "[[60531 24776]\n",
      " [    8   128]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9999    0.7096    0.8301     85307\n",
      "           1     0.0051    0.9412    0.0102       136\n",
      "\n",
      "    accuracy                         0.7099     85443\n",
      "   macro avg     0.5025    0.8254    0.4201     85443\n",
      "weighted avg     0.9983    0.7099    0.8288     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf.fit(x_train_us,y_train_us)\n",
    "y_pred = rf.predict(x_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985066c9",
   "metadata": {},
   "source": [
    "## Ada with US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "81b164e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5133363762976487\n",
      "[[43730 41577]\n",
      " [    5   131]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9999    0.5126    0.6778     85307\n",
      "           1     0.0031    0.9632    0.0063       136\n",
      "\n",
      "    accuracy                         0.5133     85443\n",
      "   macro avg     0.5015    0.7379    0.3420     85443\n",
      "weighted avg     0.9983    0.5133    0.6767     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ada.fit(x_train_us,y_train_us)\n",
    "y_pred = ada.predict(x_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5535e4",
   "metadata": {},
   "source": [
    "## GB with US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c69977da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5573891366173941\n",
      "[[47493 37814]\n",
      " [    4   132]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9999    0.5567    0.7152     85307\n",
      "           1     0.0035    0.9706    0.0069       136\n",
      "\n",
      "    accuracy                         0.5574     85443\n",
      "   macro avg     0.5017    0.7637    0.3611     85443\n",
      "weighted avg     0.9983    0.5574    0.7141     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb.fit(x_train_us,y_train_us)\n",
    "y_pred = gb.predict(x_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b13dfd9",
   "metadata": {},
   "source": [
    "## XGB with US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b74b729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:34:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhigyan/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/abhigyan/.local/lib/python3.8/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6010673782521682\n",
      "[[51226 34081]\n",
      " [    5   131]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9999    0.6005    0.7504     85307\n",
      "           1     0.0038    0.9632    0.0076       136\n",
      "\n",
      "    accuracy                         0.6011     85443\n",
      "   macro avg     0.5019    0.7819    0.3790     85443\n",
      "weighted avg     0.9983    0.6011    0.7492     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "xgb.fit(x_train_us,y_train_us)\n",
    "y_pred = xgb.predict(x_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5760f4f6",
   "metadata": {},
   "source": [
    "## Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e4a761ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c2b876d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhigyan/.local/lib/python3.8/site-packages/imblearn/utils/_validation.py:586: FutureWarning: Pass sampling_strategy=0.75 as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The samples before fit Counter({0: 199008, 1: 356})\n",
      "The samples before fit Counter({0: 199008, 1: 149256})\n"
     ]
    }
   ],
   "source": [
    "os = RandomOverSampler(0.75)\n",
    "x_train_os,y_train_os = os.fit_resample(x_train,y_train)\n",
    "print(\"The samples before fit {}\".format(Counter(y_train)))\n",
    "print(\"The samples before fit {}\".format(Counter(y_train_os)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e10e0d2",
   "metadata": {},
   "source": [
    "## Rf with OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6b8ebc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9996371850239341\n",
      "[[85302     5]\n",
      " [   26   110]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9999    0.9998     85307\n",
      "           1     0.9565    0.8088    0.8765       136\n",
      "\n",
      "    accuracy                         0.9996     85443\n",
      "   macro avg     0.9781    0.9044    0.9382     85443\n",
      "weighted avg     0.9996    0.9996    0.9996     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf.fit(x_train_os,y_train_os)\n",
    "y_pred = rf.predict(x_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d516e1",
   "metadata": {},
   "source": [
    "## Ada with OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "977e1d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9909998478517842\n",
      "[[84548   759]\n",
      " [   10   126]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9999    0.9911    0.9955     85307\n",
      "           1     0.1424    0.9265    0.2468       136\n",
      "\n",
      "    accuracy                         0.9910     85443\n",
      "   macro avg     0.5711    0.9588    0.6211     85443\n",
      "weighted avg     0.9985    0.9910    0.9943     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ada.fit(x_train_os,y_train_os)\n",
    "y_pred = ada.predict(x_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514f92b3",
   "metadata": {},
   "source": [
    "## Gb with OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "273d0095",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9938789602425009\n",
      "[[84796   511]\n",
      " [   12   124]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9999    0.9940    0.9969     85307\n",
      "           1     0.1953    0.9118    0.3217       136\n",
      "\n",
      "    accuracy                         0.9939     85443\n",
      "   macro avg     0.5976    0.9529    0.6593     85443\n",
      "weighted avg     0.9986    0.9939    0.9959     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb.fit(x_train_os,y_train_os)\n",
    "y_pred = gb.predict(x_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae74c7d",
   "metadata": {},
   "source": [
    "## XG boost with OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a023c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhigyan/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/abhigyan/.local/lib/python3.8/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:43:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.9996371850239341\n",
      "[[85296    11]\n",
      " [   20   116]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9999    0.9998     85307\n",
      "           1     0.9134    0.8529    0.8821       136\n",
      "\n",
      "    accuracy                         0.9996     85443\n",
      "   macro avg     0.9566    0.9264    0.9410     85443\n",
      "weighted avg     0.9996    0.9996    0.9996     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "xgb.fit(x_train_os,y_train_os)\n",
    "y_pred = xgb.predict(x_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd839d62",
   "metadata": {},
   "source": [
    "## SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "314576f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1d794ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The samples before fit Counter({0: 199008, 1: 356})\n",
      "The samples before fit Counter({0: 198357, 1: 198357})\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTETomek()\n",
    "x_train_sm,y_train_sm = sm.fit_resample(x_train,y_train)\n",
    "print(\"The samples before fit {}\".format(Counter(y_train)))\n",
    "print(\"The samples before fit {}\".format(Counter(y_train_sm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cebc2a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 136, 0: 85307})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab9afe9",
   "metadata": {},
   "source": [
    "## Rf with SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3a629073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9995435553526912\n",
      "[[85286    21]\n",
      " [   18   118]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9998    0.9998     85307\n",
      "           1     0.8489    0.8676    0.8582       136\n",
      "\n",
      "    accuracy                         0.9995     85443\n",
      "   macro avg     0.9244    0.9337    0.9290     85443\n",
      "weighted avg     0.9995    0.9995    0.9995     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf.fit(x_train_sm,y_train_sm)\n",
    "y_pred = rf.predict(x_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1f9d20",
   "metadata": {},
   "source": [
    "## Ada with SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "52180308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9903210327352738\n",
      "[[84490   817]\n",
      " [   10   126]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9999    0.9904    0.9951     85307\n",
      "           1     0.1336    0.9265    0.2335       136\n",
      "\n",
      "    accuracy                         0.9903     85443\n",
      "   macro avg     0.5667    0.9584    0.6143     85443\n",
      "weighted avg     0.9985    0.9903    0.9939     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ada.fit(x_train_sm,y_train_sm)\n",
    "y_pred = ada.predict(x_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4bfb4b",
   "metadata": {},
   "source": [
    "## Gb with SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9813769c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9936565897732992\n",
      "[[84776   531]\n",
      " [   11   125]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9999    0.9938    0.9968     85307\n",
      "           1     0.1905    0.9191    0.3157       136\n",
      "\n",
      "    accuracy                         0.9937     85443\n",
      "   macro avg     0.5952    0.9564    0.6562     85443\n",
      "weighted avg     0.9986    0.9937    0.9957     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb.fit(x_train_sm,y_train_sm)\n",
    "y_pred = gb.predict(x_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac521538",
   "metadata": {},
   "source": [
    "## XGB with SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "28d04f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhigyan/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/abhigyan/.local/lib/python3.8/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.9993211848834895\n",
      "[[85266    41]\n",
      " [   17   119]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9995    0.9997     85307\n",
      "           1     0.7438    0.8750    0.8041       136\n",
      "\n",
      "    accuracy                         0.9993     85443\n",
      "   macro avg     0.8718    0.9373    0.9019     85443\n",
      "weighted avg     0.9994    0.9993    0.9993     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "xgb.fit(x_train_sm,y_train_sm)\n",
    "y_pred = xgb.predict(x_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
